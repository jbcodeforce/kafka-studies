
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../strimzi/">
      
      
        <link rel="next" href="../kstreams/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.27">
    
    
      
        <title>Sizing - Apache Kafka Studies</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6543a935.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#kafka-sizing-considerations" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Apache Kafka Studies" class="md-header__button md-logo" aria-label="Apache Kafka Studies" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Apache Kafka Studies
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Sizing
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/jbcodeforce/kafka-studies.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Apache Kafka Studies" class="md-nav__button md-logo" aria-label="Apache Kafka Studies" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Apache Kafka Studies
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/jbcodeforce/kafka-studies.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://jbcodeforce.github.io/eda-studies/techno/kafka/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Apache Kafka summary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../strimzi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Strimzi
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Sizing
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Sizing
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#context" class="md-nav__link">
    <span class="md-ellipsis">
      Context
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#latency-numbers-every-solution-architect-should-know" class="md-nav__link">
    <span class="md-ellipsis">
      Latency numbers every solution architect should know
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tee-shirt-sizing" class="md-nav__link">
    <span class="md-ellipsis">
      Tee shirt sizing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#customer-assessment" class="md-nav__link">
    <span class="md-ellipsis">
      Customer Assessment
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deeper-dive-discussion" class="md-nav__link">
    <span class="md-ellipsis">
      Deeper dive discussion
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deeper dive discussion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kafka-brokers" class="md-nav__link">
    <span class="md-ellipsis">
      Kafka Brokers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardware-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Hardware considerations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-your-disk" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark your disk
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kafka-performance-testing" class="md-nav__link">
    <span class="md-ellipsis">
      Kafka performance testing
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Kafka streaming
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Kafka streaming
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://jbcodeforce.github.io/eda-studies/techno/kstreams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EDA kstreams note
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kstreams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    My notes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/jbcodeforce/kafka-streams-samples" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    My kstream samples
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/jbcodeforce/eda-kconnect-lab/tree/master/item-aggregator" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Item aggregator
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Kafka Connect
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Kafka Connect
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://jbcodeforce.github.io/eda-studies/techno/kafka-connect/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Summary
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ibm-cloud-architecture.github.io/refarch-eda/use-cases/connect-mq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MQ Labs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ibm-cloud-architecture.github.io/refarch-eda/use-cases/connect-rabbitmq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RabbitMQ Lab
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/jbcodeforce/eda-kconnect-lab" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lab repo
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    End to end code
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            End to end code
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ibm-cloud-architecture.github.io/refarch-kc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KC container
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/jbcodeforce/eda-kconnect-lab/tree/master/item-aggregator" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Item-Inventory integration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/ibm-cloud-architecture/refarch-eda-tools" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf tool and schema registry lab
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reactive with kafka
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Reactive with kafka
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://developer.ibm.com/technologies/java/articles/develop-reactive-microservices-with-microprofile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reactive messaging with microprofile
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kafka with Python
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Mirror Maker 2.0
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            Mirror Maker 2.0
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ibm-cloud-architecture.github.io/refarch-eda/technology/kafka-mirrormaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EDA note
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ibm-cloud-architecture.github.io/refarch-eda/use-cases/kafka-mm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Labs
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://jbcodeforce.github.io/kp-data-replication/monitoring" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Monitoring with Prometheus and Grafana
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#context" class="md-nav__link">
    <span class="md-ellipsis">
      Context
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#latency-numbers-every-solution-architect-should-know" class="md-nav__link">
    <span class="md-ellipsis">
      Latency numbers every solution architect should know
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tee-shirt-sizing" class="md-nav__link">
    <span class="md-ellipsis">
      Tee shirt sizing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#customer-assessment" class="md-nav__link">
    <span class="md-ellipsis">
      Customer Assessment
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deeper-dive-discussion" class="md-nav__link">
    <span class="md-ellipsis">
      Deeper dive discussion
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deeper dive discussion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kafka-brokers" class="md-nav__link">
    <span class="md-ellipsis">
      Kafka Brokers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardware-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Hardware considerations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benchmark-your-disk" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmark your disk
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kafka-performance-testing" class="md-nav__link">
    <span class="md-ellipsis">
      Kafka performance testing
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="kafka-sizing-considerations">Kafka Sizing Considerations<a class="headerlink" href="#kafka-sizing-considerations" title="Permanent link">&para;</a></h1>
<p>For any Kafka deploy we need to compute the number of brokers, connectors and replicators needed for production, staging and dev environments.</p>
<p>It is difficult to compute as Kafka has a lot of tuning factors and the needs are not easy to assess up front, during pre-sale configuration. The <a href="#tee-shirt-sizing">tee shirt</a> size is the simplest approach in pre-sale but still some important considerations need to be evaluated.</p>
<p>Generally, disk throughput tends to be the main bottleneck in Kafka performance. However, that’s not to say that the network is never a bottleneck. Network throughput can affect Kafka’s performance if you are sending messages across data centers, if your topics have a large number of consumers, or if your replica followers are catching up to their leaders.  Depending on how you configure flush behavior you may or may not benefit from more expensive disks (if you force flush often then higher RPM SAS drives may be better).</p>
<p>But what can we still do for discussion?</p>
<h2 id="context">Context<a class="headerlink" href="#context" title="Permanent link">&para;</a></h2>
<p>As stipulated by the licensing rules we need to look at brokers, geo-replicator, Prod and DR and Kafka connector. The following figure illustrates a production deployment view with the needed components to size in the context of OpenShift or Kubernetes deployment.</p>
<p><img alt="" src="images/full-prod-view.png" /></p>
<ul>
<li>The top region (Region-west) is for production. It includes OpenShift platform with master nodes (not represented in the diagram) and worker nodes. The worker nodes presented in the figure do concern only the Kafka brokers (9 dedicated nodes) and Kafka connect cluster nodes (3) that may be shared with other workload like kafka stream applications.</li>
<li>The east region is for Disaster Recovery and will have the same amount of Kafka broker nodes, they are running as they received data from the production platform.</li>
<li>The Kafka connector nodes in the DR site, are running Geo-replicator, which is based on the Mirror Maker 2 Open Source project. This component runs in cluster and will have as many nodes as needed to move to data from production topics to target topics.</li>
</ul>
<h3 id="latency-numbers-every-solution-architect-should-know">Latency numbers every solution architect should know<a class="headerlink" href="#latency-numbers-every-solution-architect-should-know" title="Permanent link">&para;</a></h3>
<p>Dr. Dean from Google reveals the length of typical computer operations in 2010. Some numbers are outdated as computers become faster and more powerful. However, those numbers should still be able to give us an idea of the fastness and slowness of different computer operations.</p>
<table>
<thead>
<tr>
<th>Operation name</th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>L1 cache reference</td>
<td>0.5 ns</td>
</tr>
<tr>
<td>L2 cache reference</td>
<td>7 ns</td>
</tr>
<tr>
<td>Mutex lock/unlock</td>
<td>100 ns</td>
</tr>
<tr>
<td>Compress 1K bytes with Zippy</td>
<td>10,000 ns = 10 µs</td>
</tr>
<tr>
<td>Send 2K bytes over 1 Gbps network</td>
<td>20,000 ns = 20 µs</td>
</tr>
<tr>
<td>Read 1 MB sequentially from memory</td>
<td>250,000 ns = 250 µs</td>
</tr>
<tr>
<td>Round trip within the same datacenter</td>
<td>500,000 ns = 500 µs</td>
</tr>
<tr>
<td>Disk seek</td>
<td>10,000,000 ns = 10 ms</td>
</tr>
<tr>
<td>Read 1 MB sequentially from the network</td>
<td>10,000,000 ns = 10 ms</td>
</tr>
<tr>
<td>Read 1 MB sequentially from disk</td>
<td>30,000,000 ns = 30 ms</td>
</tr>
<tr>
<td>Send packet CA (California) -&gt;EU -&gt;CA</td>
<td>150,000,000 ns = 150 ms</td>
</tr>
</tbody>
</table>
<details open="open">
<summary>Notes</summary>
<ul>
<li>ns = nanosecond, µs = microsecond, ms = millisecond</li>
<li>1 ns = 10^-9 seconds</li>
<li>1 µs= 10^-6 seconds = 1,000 ns</li>
<li>1 ms = 10^-3 seconds = 1,000 µs = 1,000,000 ns</li>
</ul>
</details>
<h2 id="tee-shirt-sizing">Tee shirt sizing<a class="headerlink" href="#tee-shirt-sizing" title="Permanent link">&para;</a></h2>
<p>Once you selected the starting cluster topology it is important to continuously assess the performance of the cluster, and add capacity over time. Always consider adding enough spare capacity to withstanding an event affecting all brokers of an entire Availability Zone. </p>
<p>Seimics includes a basic tee shirt cluster sizing tool. We want to update it to be more adapted to what a AWS deployment may looks like. We expect 3 availability zones, and a cluster deployed within one region for production and another one for DR. If on premise and there may no be any availability zone, so expect to get 3 racks, and so the number will be mapped to VM assign to different rack. </p>
<p>See the first figure above for a typical topology.</p>
<ul>
<li>Consumer groups up to 10</li>
</ul>
<table>
<thead>
<tr>
<th>Component</th>
<th>Small</th>
<th>Medium</th>
<th>Large</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kafka Brokers</td>
<td>4 x m5.xlarge ( 4 vCPU - 16GB)</td>
<td>9 x m5.xlarge</td>
<td>12 x m5.xlarge</td>
</tr>
<tr>
<td>Broker VPCs</td>
<td>16</td>
<td>36</td>
<td>48</td>
</tr>
<tr>
<td>Kafka Connector</td>
<td>3 x c5.large (2 CPUs - 4 GB)</td>
<td>3  x c5.large</td>
<td>6 x c5.large</td>
</tr>
<tr>
<td>KConnect VPCs</td>
<td>6</td>
<td>6</td>
<td>12</td>
</tr>
<tr>
<td>DR Kafka Brokers</td>
<td>4 x m5.xlarge ( 4 vCPU - 16G)</td>
<td>9 x m5.xlarge</td>
<td>12 x m5.xlarge</td>
</tr>
<tr>
<td>Broker VPCs</td>
<td>16</td>
<td>36</td>
<td>48</td>
</tr>
<tr>
<td>DR Kafka Connector</td>
<td>6</td>
<td>6</td>
<td>12</td>
</tr>
<tr>
<td>KConnect VPCs</td>
<td>16</td>
<td>36</td>
<td>48</td>
</tr>
<tr>
<td>DR Geo replication</td>
<td>3 c5.large (2 CPUs - 4 GB)</td>
<td>3  x c5.large</td>
<td>6  x c5.large</td>
</tr>
<tr>
<td>Geo VPCs</td>
<td>6</td>
<td>6</td>
<td>12</td>
</tr>
<tr>
<td>Zookeepers - not license</td>
<td>3 c5.large (2 CPUs - 4 GB)</td>
<td>5</td>
<td>5</td>
</tr>
<tr>
<td><strong>Grant Total VPCs</strong></td>
<td><strong>50</strong></td>
<td><strong>90</strong></td>
<td><strong>132</strong></td>
</tr>
</tbody>
</table>
<p>With m5.xlarge the expected max network throughput is:</p>
<p>To this nodes you need to add EBS and master nodes to the OpenShift cluster.</p>
<h2 id="customer-assessment">Customer Assessment<a class="headerlink" href="#customer-assessment" title="Permanent link">&para;</a></h2>
<p>We have enought concepts to discuss with architects. We need to know the following information for their target IT infrastructure. For that we sould try to work backward from their use case to determine the throughput, availability, durability, and latency requirements. Here are a set of questions to assess</p>
<ul>
<li>Are you planning to run on cloud provider or on your own hardware on-premise? If so do you have a characteristics of your hardware.</li>
</ul>
<details class="-">
<summary>Impacts</summary>
<p>As seen previously, disk, network and machine characteristics are key factor. You can use the formula of total expected cluster throughput to present the impact on those hardware characteristics. With cloud providers there are for sure a lot of different VM profile, disk storage and network capacity. It is important to assess what the customer is actually provisioning.</p>
</details>
<ul>
<li>Number of producer applications and their expected throughput in Megabyte per second - peak and average time ?</li>
</ul>
<details class="-">
<summary>Impacts</summary>
<p>This is major parameters for cluster sizing, as explained in the next section, the total throughput, impact performance, and disk sizing.</p>
</details>
<ul>
<li>What peak traffic really means ? It is important to assess how long is the peak, and how more data are sent.</li>
<li>How many hours per day / days per week the traffic is sustained?</li>
<li>Expected retention time ?  The longer the retention time, the more disk space is needed.</li>
<li>Number of different consumer types (consumer group) ?</li>
</ul>
<details class="-">
<summary>Impacts</summary>
<p>Bigger number of consumer groups will lead Kafka brokers to do a lot of processing, impacting the size of the memory and number of CPUs needed.</p>
</details>
<ul>
<li>Number of streaming apps?: this could be difficult to assess but a streaming app most likely will add topics, which may not have been seen by the customer.</li>
<li>Cloud provider</li>
</ul>
<details class="-">
<summary>Impacts</summary>
<p>This is mostly to assess the capability to select powerful virtual machine, storage area network or be able to connect disks directly to VMs.</p>
</details>
<ul>
<li>Do we need encrypted communication between apps in the same cluster: Turning on in-cluster encryption forces the brokers to encrypt and decrypt individual messages which results in additional CPU and memory bandwidth overhead.</li>
</ul>
<details class="-">
<summary>Impacts</summary>
<p>Encrypting means using bigger machine for bigger CPUs. </p>
</details>
<p>Assumptions you can share:</p>
<ul>
<li>each producer will have at least one topic</li>
<li>each streaming will add one or more topic</li>
<li>kafka connector add topics</li>
<li>topics could have two strategies: delete or compact - It will be difficult for an architect to answer what they will use. Knowing that they will have both.</li>
<li>replicas is defaulted to 3 and in-sync replicas to 2</li>
</ul>
<p>Going into details will kill any simple estimations:</p>
<ul>
<li>retention time set to multiple days may not be necessary for all topics.</li>
<li>each time we add a streaming application, we add a topic and we add files to volume.</li>
<li>compression could be used to reduce payload size</li>
<li>Each topic may have different retention, partition numbers, strategy...</li>
<li>The I/O throughput is impacted by caching strategy...</li>
</ul>
<h2 id="deeper-dive-discussion">Deeper dive discussion<a class="headerlink" href="#deeper-dive-discussion" title="Permanent link">&para;</a></h2>
<h3 id="kafka-brokers">Kafka Brokers<a class="headerlink" href="#kafka-brokers" title="Permanent link">&para;</a></h3>
<h4 id="concepts">Concepts<a class="headerlink" href="#concepts" title="Permanent link">&para;</a></h4>
<p>It is important to communicate clearly on the different elements that help to size a Kafka cluster. The following diagram presents all the needed concepts.</p>
<p><img alt="" src="images/performance.png" /></p>
<ul>
<li>On the left you will have different producer applications: any applications running Kafka Producer API, and Kafka source connectors.  Each of those application sends data which adds to the total throughput.</li>
<li>The producer applications may be a change data capture agent in Kafka Connect (e.g. <a href="https://debezium.io/">Debezium</a>), event-driven microservice apps or any Kafka source connectors. The list of producers is not exhaustive, this is used for illustration purpose.</li>
<li>Producer's throughput is impacted by a lot of parameters, one of the most important is the level of write acknowledge expected. If producer apps expect all replicas to be completed (ack=-1), to ensure no data loss, the replica and in-sync replicas settings, for each topics, are becoming important. </li>
<li>The diagram above, illustrates the minimum cluster size for high availability to support 2 failure/network isolations. Normally at least 4 nodes are recommended, as during maintenance we always want to have 3 nodes active to ensure a good availability. </li>
<li>In the figure, each horizontal cylinders are topics / partitions. For example the red topic has 3 partitions.</li>
<li>Each partition has replicas, and one broker is the partition leader (cylinder in standard color, while replicas are in sketch mode)</li>
<li>As partitions are persisted as append logs on disk, they are different factors that affect performance: the storage bandwidth of the node on which Kafka Broker runs, and the performance of the disks attached to the node. Also to be efficient, the partition to disk need to be well balanced. The storage bandwidth needs to be well known as adding more disk on a saturated bandwidth will not help.</li>
</ul>
<p><img alt="" src="images/storage-bandwidth.png" width="500" /></p>
<ul>
<li>With Cloud deployment, like AWS, the storage attached to an instance (EC2) is based on network block storage (EBS) so network throughput is also part of the equation. You may use a dedicated network between the EC2 instance and the EBS servers to isolate IO traffic. Each storage has limit on the size you can provision, therefore it is possible to run out of disk space. </li>
<li>The following figure illustrates the producer, broker operations in solution with producers sending records evenly to 3 partitions, with replica set to 3, and consumers reading from the last offset:</li>
</ul>
<p><img alt="" src="images/write-operation.png" width="700" /></p>
<ul>
<li>Each partition is save in a unique disk, so if a partition increase in a disk, the node can run out of disk space even if there is space to other attached volumes.</li>
<li>The number of consumer group impacts the broker throughput, as broker cpu will be used to manage the consumer group and partition allocation.</li>
<li>The global throughput of your cluster will be the minimum between different elements as illustrated by the following formula:</li>
</ul>
<p>$max_cluster_throughput = min($
$max(storage_throughput) * nb_brokers / replicas_factor,$
$max(san_network_throughput) * nb_brokers / replicas_factor,$ 
$max(network_throughput_ * nb_brokers / (nb_consumer _groups + replicas_factor-1))$</p>
<ul>
<li>In fact we should cap this number with a maximum percent like 80-85% of the max potential cluster throughput. In reality the cluster will process less than this theorical limit because producer may not send record well balanced and consumers can come and go.</li>
<li>Kafka was optimized to build append log, so good sequential read. Also as it uses fsynch to flush the memory to disk via OS capability write is also sequential, which increase throughput. Which also means it is not limited by disk IOPS. Consumer apps reading from the last offset will read from the memory improving throughput too. But consumers that are slow will impact the overall cluster throughput as the broker will have to load data from disk, and page the records, impact existing cache. The following figure illustrates those concepts:</li>
</ul>
<p><img alt="title" src="images/topic-persistence.png" /></p>
<ul>
<li>As illustrated in previous figure, the throughput of the storage backend depends on the data that producers are sending directly to the broker plus the replication traffic the broker is receiving from its peers.</li>
</ul>
<p>$$
storage_throughput &lt;= input_throughput * nb_brokers / replicas_factor
$$</p>
<ul>
<li>
<p>Finally as we can see a 3 broker cluster will have the real potential throughput of only <strong>one broker</strong>, as other brokers are doing partition replications. Which means if we keep 3 replicas and 2 ISR then to scale above the IOPS of one broker, we need more disk per broker and then more brokers.</p>
</li>
<li>
<p>The number of io thread to write to different disk are also limited by the number of CPUs. Below is an extract from the Event Streams cluster custom definition based on strimzi:</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">strimziOverrides</span><span class="p">:</span>
<span class="w">    </span><span class="nt">kafka</span><span class="p">:</span>
<span class="w">      </span><span class="nt">config</span><span class="p">:</span>
<span class="w">        </span><span class="nt">log.cleaner.threads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">        </span><span class="nt">num.io.threads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">        </span><span class="nt">num.network.threads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12</span>
<span class="w">        </span><span class="nt">num.replica.fetchers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">        </span><span class="nt">offsets.topic.replication.factor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">        </span><span class="nt">default.replication.factor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">        </span><span class="nt">min.insync.replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
</code></pre></div>
<ul>
<li>Streaming applications consume messages, process them and to produce in new topic: most of the time prospect has not think about those new topics.</li>
<li>Event Streams brokers run in Worker node in Kubernetes cluster. We can assume a 60-70% CPU utilization</li>
<li>The broker runs as pod, and get their volume via PVC, Persistence Volume and storage class. </li>
<li>As brokers are pods, they will have <a href="https://strimzi.io/docs/operators/latest/configuring.html#con-common-configuration-resources-reference">cpu/memory request and limit resources</a> contraint to behave well in kubernetes cluster. Here is an example of such resource constraint, but it is better to understand what is the underlying node capabilities. </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="nt">requests</span><span class="p">:</span>
<span class="w">        </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8Gi</span>
<span class="w">        </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;4&quot;</span>
<span class="w">      </span><span class="nt">limits</span><span class="p">:</span>
<span class="w">        </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">48Gi</span>
<span class="w">        </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;8&quot;</span>
</code></pre></div>
<ul>
<li>
<p>For Kafka, the following aspects of a deployment can impact the resources you need:</p>
<ul>
<li>Expected total number of message per second and size of messages</li>
<li>The number of network threads handling messages (in the cluster configuration)</li>
<li>The number of io threads handling the write operations (in the cluster configuration)</li>
<li>The number of CPUs per node.</li>
<li>Buffer flush policies</li>
<li>The number of producers and consumers</li>
<li>The number of topics and partitions</li>
</ul>
</li>
</ul>
<p>As an example on cluster with 8 CPU, 32Gb node, we can have 16 threads for the io and 32 for the network.</p>
<ul>
<li>
<p>Kafka runs inside a JVM and uses an operating system page cache to store message data before writing to disk. The memory request for Kafka should fit the JVM heap and page cache.</p>
</li>
<li>
<p>Worker node will run on physical node with multiple cores - Assumes 12 cores 48GB RAM. Remember that having bigger node will have a bigger impact to the overall cluster performance in case of failure, as more resources need to be re-allocated. On the other side, when using large node on cloud provider like AWS, we get better IO SAN (EBS) throughput, and event higher network throughput.</p>
</li>
<li>In Kubernetes, each node will have a set of PVs mounted to it - We can try to limit one disk per core, but most of the time it goes less than that. </li>
<li>Let assume 2 TB per volume.</li>
<li>
<p>On a node we may have 6 TB of disk, let say the max capacity will be at 85% so we have a capacity per node of 10.2 TB (1TB * .85 * 12).</p>
</li>
<li>
<p>With OpenShift or Kubernetes the recommendation is to use block storage and technology like IBM Spectrum, Ceph, or OCS and configure the Broker to use JBOD</p>
</li>
</ul>
<p>Recall that every broker is constrained by a particular resource (typically I/O) adding more partitions will not result in increased throughput. Instead, you need to add brokers to the cluster. So sizing will be linked to the number of disk, replicas, number of consumer groups and number of broker. With 3 brokers and 3 replicas and one disk attach per brokers the amount of data will be only 85% of &#8531; of the volume size, and throughput &#8531; of the IOPS of the disk. This is why the minimum should be 6 brokers.</p>
<p>There are other considerations when looking at the consumer profile:</p>
<ul>
<li>consumers that connect later to process older records, may lead the broker to load data from disk as most likely those records are not more in memory. The access will be non sequential read, which impact performance.</li>
</ul>
<h3 id="hardware-considerations">Hardware considerations<a class="headerlink" href="#hardware-considerations" title="Permanent link">&para;</a></h3>
<p>With OpenShift or Kubernetes deployment a lot of things need to be addressed. First we assume we deploy in one region with at least three availability zones. The figure below illustrates a AWS deployment. The Master nodes are not represented, as Event Streams / Kafka brokers run in worker nodes. A dedicated network / subnet manage the traffic between EC2 instances. The diagram illustrates 9 brokers running as worker nodes on EC2 type (m5.4xlarge).</p>
<p><img alt="" src="images/ec2-m5-types.png" /></p>
<p>There are two ways to configure storage, using instance disks, and storage area network. The EC2 I class, is for instance storage and it achieves higher IOPS and disk throughput.</p>
<p><img alt="" src="images/rosa-storage.png" /></p>
<p>Here is an example of EC2 instance, oriented I/O (I3), with large capacity, which can be considered for production deployment:</p>
<p><img alt="" src="images/ec2-i3-broker.png" /></p>
<p>It is important to note that in case of node failure, starting a new node, will lead to broker replication, which is part of the Kafka design, but still cost time to converge.</p>
<p>For SAN deployment, in AWS, EBS storage mounted to the EC2 instances. As the storage is externalized from the EC2 instance, in case of failure and recreation, the volume can be attached and the broker starts with less replication to complete.</p>
<p><img alt="" src="images/rosa-storage-ebs.png" /></p>
<p>Some EBS volume types, such as gp3, io2, and st1, also allow you to adapt the throughput and IOPS. With EBS the cluster throughput will be</p>
<p>$max_cluster_throughput = min($
$max(storage_throughput) * nb_brokers / replicas_factor,$
$max(san_network_throughput) * nb_brokers / replicas_factor)$</p>
<p>Other SAN is to use dedicated kubernetes worker nodes using the <code>rook</code> operator for k8s and <code>ceph</code> cluster:</p>
<p><img alt="" src="images/rosa-storage-ceph.png" /></p>
<p><a href="https://rook.io/docs/rook/v1.9/Getting-Started/storage-architecture/#design">Rook</a> is a cloud native storage orchestrator, which abstract the management and monitoring of storage cluster. Rook turns storage software into self-managing, self-scaling, and self-healing storage services. It uses operators. <a href="https://ceph.io/">Ceph</a> is a highly scalable distributed storage solution for block storage, object storage, and shared filesystems.
It uses its own replication mechanism, therefore will impact the overall sizing of Kafka cluster. It is not recommended to use such storage layer. </p>
<p>The figure above illustrates the rook and ceph approach.</p>
<ul>
<li>Replica on a disk has data but also index file <a href="https://kafka.apache.org/08/documentation.html#persistence">See Kafka's doc on persistence</a> which means the total size of the disk is 1.3 time greater than expected message volume.</li>
<li>Need to compute the disk size requirement per partition. But if customer communicates on total throughput, partitioning will split this amount. Still consider overhead of indexing per partition.</li>
</ul>
<p>For better performance and resilience, Strimzi recommends to use <a href="https://strimzi.io/docs/operators/latest/configuring.html#ref-jbod-storage-str">JBOD storage.</a>, so the configuration of the kafka broker looks like:</p>
<div class="highlight"><pre><span></span><code><span class="w">    </span><span class="nt">kafka</span><span class="p">:</span>
<span class="w">      </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">9</span>
<span class="w">      </span><span class="nt">storage</span><span class="p">:</span>
<span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">jbod</span>
<span class="w">        </span><span class="nt">volumes</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w">  </span>
<span class="w">          </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">localblock-sc</span>
<span class="w">          </span><span class="nt">size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2048Gi</span>
<span class="w">          </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">persistent-claim</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w"> </span>
<span class="w">          </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">localblock-sc</span>
<span class="w">          </span><span class="nt">size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2048Gi</span>
<span class="w">          </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">persistent-claim</span>
</code></pre></div>
<p>Kafka team recommends using multiple drives to get good throughput and not sharing the same drives used for Kafka data with application logs or other OS filesystem activity to ensure good latency.</p>
<p>Kafka always immediately writes all data to the filesystem (<code>/var/lib/kafka/data/kafka-log_1</code>) and supports the ability to configure the flush policy that controls when data is forced out of the OS cache and onto disk using the flush.
With the JBOD, volumes will be used by the Kafka brokers as log directories mounted into the following path: <code>/var/lib/kafka/data-id/kafka-log_idx_</code></p>
<p>Note that durability in Kafka does not require syncing data to disk, as a failed node will always recover from its replicas.</p>
<p>From AWS machine type can assume the EBS volume has a baseline throughput of 250 MB/sec from standard config and 1000 MBps for gp3 (SSD), io2 (provisioned IOPS SSD), or st1 (throughput optimized HDD) volume types. This means if we need more than a total thourghput of 200 MB/s (80% of 250) we need to add brokers to the cluster. Performance reports show a six-node cluster has almost double the throughput of the three-node cluster. Larger brokers have a higher network baseline throughput (up to 25 Gb/sec) and can therefore support more consumer groups reading from the cluster. There is no way to increase network throughput other than scaling up.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>So as a conclusion we do not recommend to use ceph for Kafka volume, and attach directly disk to the machines used for brokers deployment or use EC2 optimized for EBS volume with good IOPS. 
With strong elastic capacity like in AWS, it is relevant to select provisioned throughput using volume type io2.</p>
</div>
<p>For IBM storage class explanation and quality of service <a href="https://cloud.ibm.com/docs/containers?topic=containers-vpc-block#vpc-block-reference">see storage block note</a> 
and <a href="https://cloud.ibm.com/docs/containers?topic=containers-block_storage#block_storageclass_reference">the storage class QOS</a></p>
<h3 id="benchmark-your-disk">Benchmark your disk<a class="headerlink" href="#benchmark-your-disk" title="Permanent link">&para;</a></h3>
<p>The linux tool to test IOPS is <a href="https://github.com/axboe/fio">fio</a> (the Flexible IO Tester). In Kubernetes we can use an image and declare a PVC on the same storage class as Kafka cluster will use, and then run tests. We have defined such configuration in our gitops repositories:</p>
<ul>
<li>Update the <a href="https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops/blob/main/environments/rt-inventory-dev/env/base/diskbench.yaml">diskbench.yaml</a> file from the <a href="https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops">real time inventory gitops</a> with the storage class you are using for Event Streams.</li>
</ul>
<p>Be sure to test multiple disk sizes as most cloud providers price IOPS per GB provisioned. So a 4000Gi volume will perform better than a 1000Gi volume. </p>
<ul>
<li>Claim the PVC and start the disk bench job with:</li>
</ul>
<div class="highlight"><pre><span></span><code>oc<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>diskbench.yaml
</code></pre></div>
<ul>
<li>The Job runs a series of <code>fio</code> tests on the newly provisioned disk, currently there are 9 tests, 15s per test - total runtime is around 2.5 minutes</li>
</ul>
<p>See the <a href="https://registry.hub.docker.com/r/zayashv/dbench">Docker image for fio tool in dockerhub</a> for information on this container.</p>
<ul>
<li>Look at report:</li>
</ul>
<div class="highlight"><pre><span></span><code>oc<span class="w"> </span>logs<span class="w"> </span>-f<span class="w"> </span>job/dbench
</code></pre></div>
<p>Below is an example of <code>fio</code> report for tests on a ceph mounted disk on one of the CoC cluster:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># ... almost 100Mib/s of throughput, 1480 MB read during 15s - default block size is 4k</span>
read:<span class="w"> </span><span class="nv">IOPS</span><span class="o">=</span><span class="m">25</span>.3k,<span class="w"> </span><span class="nv">BW</span><span class="o">=</span><span class="m">98</span>.7MiB/s<span class="w"> </span><span class="o">(</span>103MB/s<span class="o">)(</span>1480MiB/15003msec<span class="o">)</span>
<span class="c1"># write almost 13Mb/s</span>
write:<span class="w"> </span><span class="nv">IOPS</span><span class="o">=</span><span class="m">3249</span>,<span class="w"> </span><span class="nv">BW</span><span class="o">=</span><span class="m">12</span>.8MiB/s<span class="w"> </span><span class="o">(</span><span class="m">13</span>.4MB/s<span class="o">)(</span>191MiB/15056msec<span class="o">)</span>
WRITE:<span class="w"> </span><span class="nv">bw</span><span class="o">=</span><span class="m">12</span>.8MiB/s<span class="w"> </span><span class="o">(</span><span class="m">13</span>.4MB/s<span class="o">)</span>,<span class="w"> </span><span class="m">12</span>.8MiB/s-12.8MiB/s<span class="w"> </span><span class="o">(</span><span class="m">13</span>.4MB/s-13.4MB/s<span class="o">)</span>,<span class="w"> </span><span class="nv">io</span><span class="o">=</span>191MiB<span class="w"> </span><span class="o">(</span>201MB<span class="o">)</span>,<span class="w"> </span><span class="nv">run</span><span class="o">=</span><span class="m">15056</span>-15056msec
<span class="c1"># read bandwidth</span>
read:<span class="w"> </span><span class="nv">IOPS</span><span class="o">=</span><span class="m">2667</span>,<span class="w"> </span><span class="nv">BW</span><span class="o">=</span>334MiB/s<span class="w"> </span><span class="o">(</span>350MB/s<span class="o">)(</span>5021MiB/15037msec<span class="o">)</span>
<span class="c1"># write</span>
write:<span class="w"> </span><span class="nv">IOPS</span><span class="o">=</span><span class="m">528</span>,<span class="w"> </span><span class="nv">BW</span><span class="o">=</span><span class="m">66</span>.6MiB/s<span class="w"> </span><span class="o">(</span><span class="m">69</span>.8MB/s<span class="o">)(</span>1004MiB/15090msec<span class="o">)</span>
<span class="c1"># Testing Read Latency...</span>
read:<span class="w"> </span><span class="nv">IOPS</span><span class="o">=</span><span class="m">3820</span>,<span class="w"> </span><span class="nv">BW</span><span class="o">=</span><span class="m">14</span>.1MiB/s<span class="w"> </span><span class="o">(</span><span class="m">15</span>.7MB/s<span class="o">)(</span>224MiB/15002msec<span class="o">)</span>
<span class="c1"># Write latency</span>
write:<span class="w"> </span><span class="nv">IOPS</span><span class="o">=</span><span class="m">1291</span>,<span class="w"> </span><span class="nv">BW</span><span class="o">=</span>5166KiB/s<span class="w"> </span><span class="o">(</span>5290kB/s<span class="o">)(</span><span class="m">75</span>.8MiB/15006msec<span class="o">)</span>
<span class="c1"># Testing Read/Write Mixed...  (may be sloser to what kafka brokers do)</span>
read:<span class="w"> </span><span class="nv">IOPS</span><span class="o">=</span><span class="m">7489</span>,<span class="w"> </span><span class="nv">BW</span><span class="o">=</span><span class="m">29</span>.3MiB/s<span class="w"> </span><span class="o">(</span><span class="m">30</span>.7MB/s<span class="o">)(</span>439MiB/15008msec<span class="o">)</span>
write:<span class="w"> </span><span class="nv">IOPS</span><span class="o">=</span><span class="m">2516</span>,<span class="w"> </span><span class="nv">BW</span><span class="o">=</span><span class="m">9</span>.86MiB/s<span class="w"> </span><span class="o">(</span><span class="m">10</span>.4MB/s<span class="o">)(</span>148MiB/15008msec<span class="o">)</span>

<span class="o">==================</span>
<span class="o">=</span><span class="w"> </span>Dbench<span class="w"> </span><span class="nv">Summary</span><span class="w"> </span><span class="o">=</span>
<span class="o">==================</span>
Random<span class="w"> </span>Read/Write<span class="w"> </span>IOPS:<span class="w"> </span><span class="m">25</span>.3k/3249.<span class="w"> </span>BW:<span class="w"> </span>334MiB/s<span class="w"> </span>/<span class="w"> </span><span class="m">66</span>.6MiB/s
Average<span class="w"> </span>Latency<span class="w"> </span><span class="o">(</span>usec<span class="o">)</span><span class="w"> </span>Read/Write:<span class="w"> </span><span class="m">1043</span>.52/
Sequential<span class="w"> </span>Read/Write:<span class="w"> </span>359MiB/s<span class="w"> </span>/<span class="w"> </span>107MiB/s
Mixed<span class="w"> </span>Random<span class="w"> </span>Read/Write<span class="w"> </span>IOPS:<span class="w"> </span><span class="m">7489</span>/2516
</code></pre></div>
<details open="open">
<summary>Interpret fio results</summary>
<ul>
<li><a href="https://tobert.github.io/post/2014-04-17-fio-output-explained.html">See this blog</a> for extended detail, but to summarize:</li>
<li>sequential read/write are important  </li>
</ul>
</details>
<ul>
<li>Be sure to clean your mess</li>
</ul>
<div class="highlight"><pre><span></span><code>oc<span class="w"> </span>delete<span class="w"> </span>-f<span class="w"> </span>diskbench.yaml
</code></pre></div>
<h3 id="kafka-performance-testing">Kafka performance testing<a class="headerlink" href="#kafka-performance-testing" title="Permanent link">&para;</a></h3>
<p>Let start by the configuration to study. Assess the Kafka Broker server.properties content which is under the <code>/opt/kafka/config</code> folder. </p>
<div class="highlight"><pre><span></span><code><span class="c1"># The number of threads that the server uses for receiving requests from the network and sending responses to the network</span>
num.network.threads<span class="o">=</span><span class="m">3</span>

<span class="c1"># The number of threads that the server uses for processing requests, which may include disk I/O</span>
num.io.threads<span class="o">=</span><span class="m">8</span>
<span class="c1"># Where data is persisted</span>
log.dirs<span class="o">=</span>/tmp/kafka-logs
<span class="c1"># The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.</span>
<span class="c1"># This value is recommended to be increased for installations with data dirs located in RAID array.</span>
num.recovery.threads.per.data.dir<span class="o">=</span><span class="m">1</span>
</code></pre></div>
<p>Consider looking at configurations which control the flush of data to disk. There are a few important trade-offs to consider:</p>
<ul>
<li><strong>Durability</strong>: Unflushed data may be lost if you are not using replication.</li>
<li><strong>Latency</strong>: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.</li>
<li><strong>Throughput</strong>: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.</li>
</ul>
<p>The settings defines the flush policy to flush data after a period of time or every N messages (or both). This can be done globally and overridden on a per-topic basis</p>
<div class="highlight"><pre><span></span><code><span class="c1"># The number of messages to accept before forcing a flush of data to disk</span>
log.flush.interval.messages<span class="o">=</span><span class="m">10000</span>
<span class="c1"># The maximum amount of time a message can sit in a log before we force a flush</span>
log.flush.interval.ms<span class="o">=</span><span class="m">1000</span>
</code></pre></div>
<ul>
<li>Create a eda-perf-topic with 5 partitions and 3 replicas (example in <a href=""></a>)</li>
</ul>
<div class="highlight"><pre><span></span><code>oc<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>eda-perf-topic.yaml
</code></pre></div>
<p>Use internal producer perf test tool:</p>
<div class="highlight"><pre><span></span><code>./kafka-producer-perf-test.sh<span class="w"> </span>--topic<span class="w"> </span>eda-perf-test<span class="w"> </span>--num-records<span class="w"> </span><span class="m">20000</span><span class="w"> </span>--record-size<span class="w"> </span><span class="m">1000</span><span class="w"> </span>--print-metrics<span class="w"> </span>--throughput<span class="w"> </span><span class="m">300</span><span class="w"> </span>--producer-props<span class="w"> </span>bootstrap.servers<span class="o">=</span>dev-kafka-bootstrap.rt-inventory-dev.svc:9092
</code></pre></div>
<ul>
<li>interesting metrics to look at:</li>
</ul>
<div class="highlight"><pre><span></span><code>producer-metrics:connection-count:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                              </span>:<span class="w"> </span><span class="m">4</span>.000

producer-metrics:incoming-byte-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                            </span>:<span class="w"> </span><span class="m">18259</span>.896
producer-metrics:incoming-byte-total:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                           </span>:<span class="w"> </span><span class="m">1192836</span>.000

producer-metrics:io-ratio:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                                      </span>:<span class="w"> </span><span class="m">0</span>.042
producer-metrics:io-time-ns-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                                </span>:<span class="w"> </span><span class="m">51450</span>.563
producer-metrics:io-time-ns-total:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                              </span>:<span class="w"> </span><span class="m">3055959438</span>.000
producer-metrics:io-wait-ratio:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                                 </span>:<span class="w"> </span><span class="m">0</span>.919
producer-metrics:io-wait-time-ns-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                           </span>:<span class="w"> </span><span class="m">1122985</span>.600
producer-metrics:io-wait-time-ns-total:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                         </span>:<span class="w"> </span><span class="m">59169150670</span>.000
producer-metrics:io-waittime-total:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                             </span>:<span class="w"> </span><span class="m">59169150670</span>.000

producer-metrics:network-io-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                               </span>:<span class="w"> </span><span class="m">570</span>.384
producer-metrics:network-io-total:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                              </span>:<span class="w"> </span><span class="m">37198</span>.000

producer-metrics:record-queue-time-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                         </span>:<span class="w"> </span><span class="m">0</span>.095
producer-metrics:record-queue-time-max:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                         </span>:<span class="w"> </span><span class="m">7</span>.000
<span class="c1"># record throughtput was set to 300 so simulator was close</span>
producer-metrics:record-send-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                              </span>:<span class="w"> </span><span class="m">299</span>.867
producer-metrics:record-send-total:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                             </span>:<span class="w"> </span><span class="m">20000</span>.000
producer-metrics:record-size-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                               </span>:<span class="w"> </span><span class="m">1086</span>.000
producer-metrics:record-size-max:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                               </span>:<span class="w"> </span><span class="m">1086</span>.000
<span class="c1"># Latency cross nodes, then with at node level</span>
producer-metrics:request-latency-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                           </span>:<span class="w"> </span><span class="m">3</span>.499
producer-metrics:request-latency-max:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                           </span>:<span class="w"> </span><span class="m">38</span>.000
producer-node-metrics:request-latency-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-0<span class="o">}</span><span class="w">      </span>:<span class="w"> </span><span class="m">4</span>.091
producer-node-metrics:request-latency-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-1<span class="o">}</span><span class="w">      </span>:<span class="w"> </span><span class="m">3</span>.105
producer-node-metrics:request-latency-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-2<span class="o">}</span><span class="w">      </span>:<span class="w"> </span><span class="m">3</span>.589
producer-node-metrics:request-latency-max:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-0<span class="o">}</span><span class="w">      </span>:<span class="w"> </span><span class="m">20</span>.000
producer-node-metrics:request-latency-max:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-1<span class="o">}</span><span class="w">      </span>:<span class="w"> </span><span class="m">18</span>.000
producer-node-metrics:request-latency-max:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-2<span class="o">}</span><span class="w">      </span>:<span class="w"> </span><span class="m">38</span>.000

producer-metrics:request-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                                  </span>:<span class="w"> </span><span class="m">285</span>.192
producer-metrics:request-size-avg:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                              </span>:<span class="w"> </span><span class="m">1188</span>.969
producer-metrics:request-size-max:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client<span class="o">}</span><span class="w">                              </span>:<span class="w"> </span><span class="m">2214</span>.000
producer-node-metrics:request-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-0<span class="o">}</span><span class="w">             </span>:<span class="w"> </span><span class="m">58</span>.021
producer-node-metrics:request-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-1<span class="o">}</span><span class="w">             </span>:<span class="w"> </span><span class="m">113</span>.459
producer-node-metrics:request-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-2<span class="o">}</span><span class="w">             </span>:<span class="w"> </span><span class="m">113</span>.795

producer-node-metrics:response-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-0<span class="o">}</span><span class="w">            </span>:<span class="w"> </span><span class="m">58</span>.027
producer-node-metrics:response-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-1<span class="o">}</span><span class="w">            </span>:<span class="w"> </span><span class="m">113</span>.411
producer-node-metrics:response-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span>node-id<span class="o">=</span>node-2<span class="o">}</span><span class="w">            </span>:<span class="w"> </span><span class="m">113</span>.805
producer-topic-metrics:byte-rate:<span class="o">{</span>client-id<span class="o">=</span>perf-producer-client,<span class="w"> </span><span class="nv">topic</span><span class="o">=</span>eda-perf-test<span class="o">}</span><span class="w">          </span>:<span class="w"> </span><span class="m">319971</span>.654
</code></pre></div>
<details class="-">
<summary>Read more</summary>
<ul>
<li><a href="https://kafka.apache.org/documentation/#hwandos">Kafka doc on hardware and OS need</a></li>
<li><a href="https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/">Datadog article: Monitoring Kafka performance metrics</a></li>
</ul>
</details>
<details class="-">
<summary>More Reading</summary>
<ul>
<li><a href="https://strimzi.io/docs/operators/latest/configuring.html#assembly-config-kafka-str">Strimzi configuration</a></li>
<li><a href="https://developer.confluent.io/learn/kafka-performance/">Kafka performance test tool</a></li>
<li><a href="https://aws.amazon.com/blogs/big-data/best-practices-for-right-sizing-your-apache-kafka-clusters-to-optimize-performance-and-cost/">AWS Best practices for right-sizing your Apache Kafka clusters to optimize performance and cost</a></li>
<li><a href="https://github.com/ibm-cloud-architecture/refarch-eda-tools">Our testing tool</a></li>
<li><a href="https://github.com/aws-samples/performance-testing-framework-for-apache-kafka/">AWS perf testing framework for Kafka</a></li>
<li>For <a href="https://cloud.ibm.com/docs/containers?topic=containers-vpc-block#vpc-block-reference">IBM storage class explanation</a> </li>
</ul>
</details>
<p>and <a href="https://cloud.ibm.com/docs/containers?topic=containers-block_storage#block_storageclass_reference">the storage class QOS</a></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.ad660dcc.min.js"></script>
      
    
  </body>
</html>